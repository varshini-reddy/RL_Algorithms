{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "\n",
                "from gym import Env\n",
                "from gym.spaces import Discrete, Box \n",
                "import numpy as np\n",
                "import random\n",
                "import gym\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Possible directions of the wind in the horizontal axis\n",
                "wind_direction_horizontal = [\"North\",\"South\",\"East\",\"West\"]\n",
                "\n",
                "# Possible direction of the wind in the vertical axis\n",
                "wind_direction_vertical = [\"Up\",\"Down\",\"None\"]\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## GYM ENVIRONMENT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Class that defines the helicopter environment inherit from openAIs environment class\n",
                "class HelicopterSpace(Env):\n",
                "\n",
                "  # The init function of the environment class\n",
                "  def __init__(self):\n",
                "\n",
                "    # The possible observation space is x(0,100), y(0,100) and h(500,550)\n",
                "    self.observation_space = Box(np.array([0,0,500]), np.array([100,100,550]))\n",
                "\n",
                "    # Possible action i.e. the acceleration \n",
                "    self.action_space = Box(np.array([1]), np.array([10]))\n",
                "    \n",
                "    # State is an array of x position, y position and height from ground\n",
                "    # The start state of the helicopter is (0,0) at a height of 525\n",
                "    self.state = [0,0,525]\n",
                "    \n",
                "    # Initial reward is 0\n",
                "    self.reward = 0\n",
                "    \n",
                "    #Initial velocity is 0\n",
                "    self.initial_velocity = 0\n",
                "\n",
                "    \n",
                "  # Function to get the variables elements of the environment\n",
                "  def variable_envo(self):\n",
                "        \n",
                "    # Get the direction of wind in the horizontal direction randomly from the wind_direction_horizontal list\n",
                "    wdh = np.random.choice(wind_direction_horizontal)\n",
                "    \n",
                "    # Get the direction of wind in the vertical direction randomly from the wind_direction_vertical list\n",
                "    wdv = np.random.choice(wind_direction_vertical)\n",
                "    \n",
                "    # Get the wind speed randomly between 0.1 and 5\n",
                "    ws = np.random.uniform(0.1,5)\n",
                "    \n",
                "    return wdh, wdv, ws\n",
                "    \n",
                "    \n",
                "  # Step function each time there is an action\n",
                "  def step(self, action):\n",
                "    \n",
                "    # Call the function to get the variable elements of the environment\n",
                "    wdh, wdv, ws = self.variable_envo()\n",
                "    \n",
                "    # Get the action of the environment passed as a parameter to this function\n",
                "    self.action = action\n",
                "    \n",
                "    # Set the current state of the environment as the previous state\n",
                "    prev_state = self.state\n",
                "\n",
                "    # Call the function compute_position to get the new helicopter position\n",
                "    x,y,h,u = self.compute_position(wdh, wdv, ws)\n",
                "    \n",
                "    # Update the state of the environment\n",
                "    self.state = [x,y,h]\n",
                "    \n",
                "    # Update the initial velocity with the cuurent value\n",
                "    self.initial_velocity = u\n",
                "\n",
                "    # Conditions to update the reward\n",
                "    if (self.state[0]\u003e=90 and self.state[0]\u003c=100) and (self.state[1]\u003e=90 and self.state[1]\u003c=100) and (self.state[2]\u003e=520 and self.state[2]\u003c=540):\n",
                "      self.reward = self.reward + 1000\n",
                "      done=True\n",
                "\n",
                "    elif self.state[0]\u003e110 or self.state[1]\u003e110 or self.state[2]\u003c490 or self.state[2]\u003e570:\n",
                "      self.reward = self.reward - 10\n",
                "      done = True \n",
                "\n",
                "    elif self.state[0]\u003c0 or self.state[0]\u003e100 or self.state[1]\u003c0 or self.state[1]\u003e100 or self.state[2]\u003c500 or self.state[2]\u003e550:\n",
                "      self.reward = self.reward - 10\n",
                "      done = False\n",
                "\n",
                "    elif self.state[0]\u003cprev_state[0] or self.state[1]\u003cprev_state[1]:\n",
                "      self.reward = self.reward - 2\n",
                "      done = False\n",
                "\n",
                "    else:\n",
                "      self.reward = self.reward + 1\n",
                "      done = False\n",
                "\n",
                "    return self.state, self.reward, done\n",
                "\n",
                "  # Function to compute the new position of the helicopter\n",
                "  def compute_position(self,wdh,wdv,ws):\n",
                "    \n",
                "    # Get the current position of the helicopter\n",
                "    x = self.state[0] \n",
                "    y = self.state[1]\n",
                "    h = self.state[2]\n",
                "      \n",
                "    # Acceleration is the rate of change of velocity\n",
                "    # acc = (v - u)/ (t_2 - t_1);  (t_2 - t_1)=1\n",
                "    # v = acc + u\n",
                "    v = self.action + self.initial_velocity\n",
                "\n",
                "    # Displacement due to the acceleration\n",
                "    # d is the distance = speed * time\n",
                "    d = v*(1) \n",
                "\n",
                "    # Displacement caused by the wind\n",
                "    dis = 0.7*ws\n",
                "\n",
                "    # Get the new position of the helicopter based on the wind direction\n",
                "    if wdh==\"East\":\n",
                "        x = x + d + dis\n",
                "        y = y + d\n",
                "\n",
                "    elif wdh==\"West\":\n",
                "        x = x + d - dis\n",
                "        y = y + d \n",
                "\n",
                "    elif wdh==\"North\":\n",
                "        x = x + d\n",
                "        y = y + d + dis\n",
                "\n",
                "    elif wdh==\"South\":\n",
                "        x = x + d\n",
                "        y = y + d - dis\n",
                "\n",
                "    if wdv==\"Up\":\n",
                "        h = h + dis\n",
                "\n",
                "    elif wdv==\"Down\":\n",
                "        h = h - dis\n",
                "\n",
                "    elif wdv==\"None\":\n",
                "        h = h\n",
                "\n",
                "    # Return the new position along with the velocity\n",
                "    return x,y,h,v\n",
                "\n",
                "\n",
                "  # The reset function which is set to the initial values\n",
                "  def reset(self):\n",
                "    self.state = [0,0,525]\n",
                "    self.reward = 0\n",
                "    self.initial_velocity = 0\n",
                "    done = False\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## TEST THE ENVIRONMENT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The reward of this episode is: -15\n"
                }
            ],
            "source": [
                "# Create an instance of the custom environment\n",
                "env = HelicopterSpace()\n",
                "\n",
                "# Number of episodes\n",
                "episodes = 1\n",
                "\n",
                "# Set done as False\n",
                "done = False\n",
                "\n",
                "# Loop over all the steps\n",
                "for i in range(episodes):\n",
                "\n",
                "  # Set the intial number of seconds to reach your goal \n",
                "  step = 1\n",
                "\n",
                "  # Set done as False\n",
                "  done = False\n",
                "    \n",
                "  # Loop over the entire episode or until the maximum number of seconds to reach your goal \n",
                "  while done!=True and step\u003c200:\n",
                "\n",
                "    step+= 1\n",
                "\n",
                "    # Sample an action from the action_space of the environment\n",
                "    action = env.action_space.sample()\n",
                "\n",
                "    # Call the step function within the environment\n",
                "    state, reward, done = env.step(action)\n",
                "    \n",
                "  # Print the reward at the end of each episode\n",
                "  print(\"The reward of this episode is:\",reward)\n",
                "\n",
                "  # Call the reset function at the end of an episode\n",
                "  env.reset()\n",
                ""
            ]
        }
    ]
}
