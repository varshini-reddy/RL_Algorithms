{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1,
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import gym\n",
                "import random\n",
                "import numpy as np\n",
                "from gym import Env\n",
                "from gym.spaces import Discrete, Box \n",
                "from helper import transition_rules, reward_rules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Class MouseGrid that inherits from OpenAI Gym Env\n",
                "class MouseGrid(Env):\n",
                "\n",
                "  # Constructor that is called when an instance of the class is created\n",
                "  def __init__(self):\n",
                "\n",
                "    # Set the observation_space i.e the state to 16 discrete values\n",
                "    self.observation_space = Discrete(16)\n",
                "\n",
                "    # Set the action space to 4 discrete values i.e up, left, right and down \n",
                "    self.action_space = Discrete(4)\n",
                "\n",
                "    # Set the initial state of the mouse to 1\n",
                "    self.state = 1\n",
                "\n",
                "    # Set the initial reward as 0\n",
                "    self.reward = 0\n",
                "\n",
                "  # Define a function step that inputs an action and updates the reward\n",
                "  def step(self, action):\n",
                "\n",
                "    # Update the action to the action sent as the parameter of this function\n",
                "    self.action = action\n",
                "\n",
                "    # Set a variable prev_state as the current state of the environment\n",
                "    prev_state = self.state\n",
                "\n",
                "    # Update the state based on the current state and action by \n",
                "    # calling the transition_rules function with the current state and action\n",
                "    self.state = transition_rules(self.state, self.action)\n",
                "\n",
                "    # Update the reward by calling the function reward_rules by passing\n",
                "    # the current state and previous state\n",
                "    self.reward = self.reward + reward_rules(self.state, prev_state)\n",
                "\n",
                "    # If the current state is 16 that means our mouse has reached the goal\n",
                "    # For this, we set the call the reward_rules function again\n",
                "    # Set done as True\n",
                "    if self.state==16:\n",
                "      self.reward = self.reward + reward_rules(self.state, prev_state)\n",
                "      done = True\n",
                "\n",
                "    # Else set done as false\n",
                "    else:\n",
                "      done = False\n",
                "\n",
                "    # Return the state, reward and done to indicate whether an episode is complete\n",
                "    return self.state, self.reward, done\n",
                "\n",
                "\n",
                "  # The reset function which is called at the end of each episode\n",
                "  def reset(self):\n",
                "\n",
                "    # Reset the initial state to the start point\n",
                "    self.state=1\n",
                "\n",
                "    # Reset the reward to 0\n",
                "    self.reward = 0\n",
                "\n",
                "    # Set done as False\n",
                "    done = False\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## SET THE AGENT TO TEST THE ENVIRONMENT"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "The reward of this episode is: -142\nThe reward of this episode is: -14\nThe reward of this episode is: -300\nThe reward of this episode is: -61\nThe reward of this episode is: -876\nThe reward of this episode is: 205\nThe reward of this episode is: -7\nThe reward of this episode is: 109\nThe reward of this episode is: 48\nThe reward of this episode is: -37\n"
                }
            ],
            "source": [
                "# Create an instance of the custom environment\n",
                "env = MouseGrid()\n",
                "\n",
                "# Set the maximum number of episodes to any integer between 10 and 50\n",
                "episodes = 10\n",
                "\n",
                "# Loop over all the steps\n",
                "for i in range(episodes):\n",
                "\n",
                "  # Set done as False to run until the end of the episode\n",
                "  done = False\n",
                "\n",
                "  # Loop over the entire episode\n",
                "  while done!=True:\n",
                "\n",
                "    # Sample an action from the action_space of the environment\n",
                "    action = env.action_space.sample()\n",
                "\n",
                "    # Call the step function within the environment\n",
                "    state, reward, done = env.step(action)\n",
                "\n",
                "  # Call the reset function at the end of an episode\n",
                "  env.reset()\n",
                "\n",
                "  # Print the reward at the end of each episode\n",
                "  print(\"The reward of this episode is:\",reward)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ⏸ Here we are using random sampling to pick an action for a given state. However, if you had a policy, which part of the exercise would you change to incorporate it?\n",
                "\n",
                "#### A. The step() method of the MouseGrid class.\n",
                "#### B. self.action within the __init__() method of the MouseGrid class.\n",
                "#### C. getting an action for each step within the for loop over all episodes.\n",
                "#### D. Call to the step() method in the last cell. \n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow1) ###\n",
                "# Submit an answer choice as a string below (eg. if you choose option A, put 'A')\n",
                "answer1 = 'C'\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ⏸ Which of the following would be an issue if the reset() method is not called at the end of each episode?\n",
                "\n",
                "#### A. The next episode will not run as the state is 16.\n",
                "#### B. The action sampled next will be biased on the previous value.\n",
                "#### C. The reward of the new episode will be combined to the reward of the previous episode.\n",
                "#### D. The reset() method does not affect anything."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "### edTest(test_chow2) ###\n",
                "# Submit an answer choice as a string below \n",
                "# There can be multiple correct answers. Replace the options with a hyphen\n",
                "# For example if you think the correct choice is A and D, then type 'A-D'\n",
                "answer2 = 'A-C'"
            ]
        }
    ]
}
